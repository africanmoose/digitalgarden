---
{"dg-publish":true,"permalink":"/1x - References/11 Notes/11.03 Ideas/Information is only information if it is Surprising/","title":"Information is only information if it is Surprising","noteIcon":"","created":"2022-11-05T18:20:25.000+03:00","updated":"2024-02-14T20:18:29.353+03:00"}
---


### Summary
- We can measure how much information is passed by how surprising it is.
- something not surprising is not information - we expected it

### Details
- "Information is defined as the measure of the decrease of uncertainty for a receiver. The amount of Shannon information is inversely proportional to the probability of the occurrence of that information"

### References
- https://en.wikipedia.org/wiki/Entropy_(information_theory)

### Interesting Related
- [[1x - References/11 Notes/11.03 Ideas/Zettelkasten Method\|Zettelkasten Method]]
- [[1x - References/11 Notes/11.05 Persons/Claude Shannon\|Claude Shannon]]
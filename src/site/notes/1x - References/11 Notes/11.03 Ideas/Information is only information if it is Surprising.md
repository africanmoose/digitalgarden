---
{"dg-publish":true,"permalink":"/1x-references/11-notes/11-03-ideas/information-is-only-information-if-it-is-surprising/","noteIcon":""}
---


### Summary
- We can measure how much information is passed by how surprising it is.
- something not surprising is not information - we expected it

### Details
- "Information is defined as the measure of the decrease of uncertainty for a receiver. The amount of Shannon information is inversely proportional to the probability of the occurrence of that information"

### References
- https://en.wikipedia.org/wiki/Entropy_(information_theory)

### Interesting Related
- [[1x - References/11 Notes/11.03 Ideas/Zettelkasten Method\|Zettelkasten Method]]
- [[1x - References/11 Notes/11.05 Persons/Claude Shannon\|Claude Shannon]]